#================================åŒ¯å…¥å‡½æ•¸===============================
import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report,roc_curve, roc_auc_score
from xgboost import XGBClassifier
import matplotlib.pyplot as plt
import seaborn as sns
import shap
import os
#======================================================================

df = pd.read_csv("D:/AI_prediction/python_program/program1/new_all_teams_data.csv", encoding="utf-8-sig")
df = np.round(df, 3) # æ”¹è®Šè³‡æ–™åªåˆ°å°æ•¸ç¬¬ä¸‰ä½

X = df.drop(columns=["result"], axis=1)  # ç‰¹å¾µæ¬„ä½ï¼Œaxis=1(æ¬„ä½)åˆªæ‰resultæ¬„ä½ã€‚
y = df["result"]                 # æ¨™ç±¤æ¬„ä½

#================================åˆ†å‰²è³‡æ–™ç‚ºè¨“ç·´é›†å’Œæ¸¬è©¦é›†===============================
# stratify=yæŒ‰ç…§yçš„åˆ†å¸ƒä¾†åˆ‡åˆ†è³‡æ–™ï¼Œä¿æŒè¨“ç·´å’Œæ¸¬è©¦è³‡æ–™çš„å‹è² æ¯”ä¾‹ç›¸åŒã€‚
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
) 
#===================================================================================

#================================å»ºç«‹æ¨¡å‹===============================
xgb_model = XGBClassifier(
    objective='binary:logistic',  # äºŒå…ƒåˆ†é¡
    eval_metric='logloss',        # æå¤±å‡½æ•¸
    n_estimators=100,             # æ¨¹çš„æ•¸é‡
    max_depth=5,                  # æ¨¹æ·±åº¦(å±¤æ•¸)
    learning_rate=0.1,            # å­¸ç¿’ç‡
    random_state=42
)
#======================================================================

#================================è¨“ç·´æ¨¡å‹===============================
xgb_model.fit(X_train, y_train)
#======================================================================

#================================å°å‡ºè³‡è¨Š======================================
# é æ¸¬
y_pred = xgb_model.predict(X_test)

# æº–ç¢ºç‡
acc = accuracy_score(y_test, y_pred)
print("Accuracy:", acc)

# æ··æ·†çŸ©é™£
cm = confusion_matrix(y_test, y_pred) # è¨ˆç®—æ··æ·†çŸ©é™£
print("Confusion Matrix:\n", cm)

# è©³ç´°åˆ†é¡å ±å‘Š
print(classification_report(y_test, y_pred, digits=4))
#=============================================================================

#================================5-fold cross-validation======================
scores = cross_val_score(xgb_model, X, y, cv=5, scoring='accuracy')
print("æ¯ä¸€ fold çš„æº–ç¢ºç‡:", scores)
print("å¹³å‡æº–ç¢ºç‡:", np.mean(scores))
#=============================================================================

#================================æ··æ·†çŸ©é™£åœ–======================
plt.figure(figsize=(6,4)) # å¯¬6å‹ ã€ é«˜4å‹
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues") # sns.heatmap()ç•«ç†±åŠ›åœ–ç”¨ ã€ annot=True(æ¯å€‹æ ¼å­ä¸­æ˜¯å¦é¡¯ç¤ºæ•¸æ“š) ã€ fmt="d"(æ ¼å­ä¸­çš„æ•¸å­—é¡¯ç¤ºæ•´æ•¸) ã€ cmap="Blues"(é¡¯ç¤ºåœ–ç‚ºè—è‰²ä¸»é¡Œ)
plt.title("Confusion Matrix")
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.tight_layout()
plt.savefig(("XGBoost_image/confusion_matrix.png"), dpi=150)
plt.close()
print("Confusion matrix saved as confusion_matrix.png\n")
#==============================================================

#===========================5-fold æº–ç¢ºç‡åœ–==================
plt.figure(figsize=(6,4))
plt.bar(range(1,6), scores) #plt.bar()ç•«é•·æ¢åœ–ç”¨ ã€ range(1,6)é€™å€‹æ˜¯Xè»¸åº§æ¨™ ã€ scoresé€™å€‹æ˜¯yè»¸åº§æ¨™(5æ¬¡çš„æº–ç¢ºç‡)
plt.title("5-Fold Cross-Validation Accuracy")
plt.xlabel("Fold")
plt.ylabel("Accuracy")
plt.ylim(0,1)      # è¨­å®š y è»¸çš„ç¯„åœï¼ˆä¸Šä¸‹é™ï¼‰
plt.tight_layout() # è‡ªå‹•èª¿æ•´åœ–è¡¨çš„ç©ºé–“é…ç½®
plt.savefig("XGBoost_image/cross_val_accuracy.png", dpi=150)
plt.close()
print("Cross-validation plot saved as cross_val_accuracy.png\n")
#=========================================================

#==================================ROC Curveåœ–=====================================
y_prob = xgb_model.predict_proba(X_test)[:, 1] # y_probæ¨¡å‹é æ¸¬è´çš„æ©Ÿç‡

fpr, tpr, thresholds = roc_curve(y_test, y_prob)
auc = roc_auc_score(y_test, y_prob)

plt.figure(figsize=(6,5))
plt.plot(fpr, tpr, label=f"XGBoost (AUC = {auc:.4f})")
plt.plot([0,1], [0,1], 'k--', label="Random")
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curve")
plt.legend() # é¡¯ç¤ºåœ–ä¾‹
plt.tight_layout() # è‡ªå‹•èª¿æ•´åœ–è¡¨çš„ç©ºé–“é…ç½®
plt.savefig("XGBoost_image/ROC_curve.png", dpi=150)
plt.close()
print("ROC_curve plot saved as ROC_curve.png\n")
#==============================================================================

#==================================ç‰¹å¾µé‡è¦åº¦åœ–=====================================
importance = xgb_model.feature_importances_ # å–å¾—æ¯å€‹ç‰¹å¾µçš„é‡è¦åº¦åˆ†æ•¸ï¼ˆ0~1ä¹‹é–“ï¼‰
features = X.columns # å–å¾—ç‰¹å¾µåç¨±

# æ’åºå¾Œç•«åœ–
indices = np.argsort(importance)[::-1]

plt.figure(figsize=(10,6))
plt.bar(range(len(features)), importance[indices]) # range(len(features))ç‰¹å¾µæ•¸é‡ ã€ importance[indices]æŒ‰ç…§æ’åºå¾Œçš„é‡è¦åº¦ç´¢å¼•å–å‡ºæ•¸å€¼ç•«å‡ºé•·æ¢åœ–ã€‚
plt.xticks(range(len(features)), features[indices], rotation=90) # range(len(features))ç‰¹å¾µæ•¸é‡ ã€ features[indices]ç”±ç‰¹å¾µæ¬Šé‡å¤§åˆ°å°æ’åºåˆ°Xè»¸(ç‰¹å¾µåç¨±) ã€ rotation=90æŠŠæ–‡å­—æ—‹è½‰ 90 åº¦ï¼ˆç›´ç«‹é¡¯ç¤ºï¼‰
plt.title("XGBoost Feature Importance")
plt.tight_layout()
plt.savefig("XGBoost_image/Feature_importance.png", dpi=150)
plt.close()
print("Feature_importance plot saved as Feature_importance.png\n")
#=================================================================================

#==================================SHAPè§£é‡‹=====================================
explainer = shap.TreeExplainer(xgb_model)
shap_values = explainer.shap_values(X_test)

# ----------------------------
# 1. å…¨åŸŸç‰¹å¾µé‡è¦åº¦ (bar plot)ã€‚ Bar plot æ˜¯ å–å¹³å‡çµ•å°å€¼ï¼Œæ‰€ä»¥åªé¡¯ç¤ºã€Œå½±éŸ¿åŠ›å¤§å°ã€ï¼Œä¸æœƒé¡¯ç¤ºå¢åŠ æˆ–é™ä½å‹ç‡ã€‚
#å‡è¨­ç‰¹å¾µ ğ‘— çš„ 5 å€‹æ¨£æœ¬ SHAP å€¼å¦‚ä¸‹ï¼š
#Ï•jâ€‹=[0.2,âˆ’0.3,0.1,âˆ’0.1,0.5] ç›¸åŒç‰¹å¾µçš„SHAPå€¼ï¼Œâˆ£0.2âˆ£ âˆ’ âˆ£0.3âˆ£ + âˆ£0.1âˆ£ âˆ’ âˆ£0.1âˆ£ + âˆ£0.5âˆ£â€‹ / 5 = 0.08
# ----------------------------
plt.figure()
shap.summary_plot(shap_values, X_test, plot_type="bar", show=False)  # show=False ä¸ç›´æ¥é¡¯ç¤º
plt.savefig("XGBoost_image/shap_summary_bar.png", dpi=150, bbox_inches='tight')     # å­˜æˆ PNG
plt.close()  # é‡‹æ”¾åœ–å½¢è³‡æº
print("shap_summary_bar plot saved as shap_summary_bar.png\n")

# ----------------------------
# 2. è©³ç´° SHAP åˆ†ä½ˆ (dot plot)
# ----------------------------
plt.figure()
shap.summary_plot(shap_values, X_test, show=False)
plt.savefig("XGBoost_image/shap_summary_dot.png", dpi=150, bbox_inches='tight')
plt.close()  # é‡‹æ”¾åœ–å½¢è³‡æº
print("shap_summary_dot plot saved as shap_summary_dot.png\n")
#===============================================================================